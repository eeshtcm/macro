import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# ---------------- CONFIG ----------------
BASELINE_REL = 0          # 0 = auction-day baseline; set -1 for day-before
WINDOW = (-8, 8)          # T-8 ... T+8
IN_BP = True
# Your screenshots show yld ~0.3–0.6 (i.e., 0.30%), so 1pp = 100bp:
BP_SCALE = 100.0

# ---------------- 0) QUICK SANITY ----------------
# Do NOT overwrite swap dates with auction dates anywhere!
# Make sure all dates are real datetimes (not dt.date)
gilt_df = gilt_df.copy()
swap_df = swap_df.copy()
calendar_df = calendar_df.copy()

gilt_df["date"] = pd.to_datetime(gilt_df["date"], errors="coerce").dt.normalize()
swap_df["date"] = pd.to_datetime(swap_df["date"], errors="coerce").dt.normalize()
calendar_df["auction_dt"] = pd.to_datetime(calendar_df["auction_dt"], errors="coerce").dt.normalize()

# ---------------- 1) GILTS: parse maturity & TTM ----------------
def _parse_maturity_date_from_series(series: pd.Series) -> pd.Series:
    # DD-Mmm-YYYY inside the series_id: e.g., '31-Jul-2035'
    pat = re.compile(r'(\d{2}-[A-Za-z]{3}-\d{4})')
    dt = series.str.extract(pat, expand=False)
    return pd.to_datetime(dt, dayfirst=True, errors="coerce")

g = gilt_df.copy()
if "maturity_date" not in g.columns:
    g["maturity_date"] = _parse_maturity_date_from_series(g["series_id"])
    # fallback if parsing fails: use mid-July of maturity_year
    mfail = g["maturity_date"].isna() & g["maturity_year"].notna()
    g.loc[mfail, "maturity_date"] = pd.to_datetime(
        g.loc[mfail, "maturity_year"].astype(int).astype(str) + "-07-15"
    )

# time-to-maturity in years (ACT/365)
g["tenor_years"] = (g["maturity_date"] - g["date"]).dt.days / 365.0
# drop obvious junk rows
g = g.dropna(subset=["series_id","date","yld","tenor_years"]).copy()

# ---------------- 2) SWAPS: clean & prepare ----------------
# In your swaps table: yld is the SONIA *par* mid rate at that tenor
s = swap_df.rename(columns={"yld":"swap_rate"}).copy()
s["tenor_years"] = pd.to_numeric(s["tenor_years"], errors="coerce")
s = s.dropna(subset=["date","tenor_years","swap_rate"])

# collapse duplicates per (date, tenor) and sort
s = (s.groupby(["date","tenor_years"], as_index=False)["swap_rate"]
       .mean()
       .sort_values(["date","tenor_years"]))

# ---------------- 3) Attach swap @ gilt TTM (daily interpolation) ----------------
def attach_swap_at_tenor(gilts: pd.DataFrame, swaps: pd.DataFrame) -> pd.DataFrame:
    out = []
    for d, gg in gilts.groupby("date", sort=False):
        curve = swaps.loc[swaps["date"] == d, ["tenor_years","swap_rate"]]
        curve = curve.drop_duplicates(subset=["tenor_years"]).sort_values("tenor_years")
        if len(curve) < 2:
            # not enough points to interpolate; skip this day
            continue
        x = curve["tenor_years"].to_numpy(dtype=float)
        y = curve["swap_rate"].to_numpy(dtype=float)
        tgt = gg["tenor_years"].to_numpy(dtype=float)
        tgt = np.clip(tgt, x.min(), x.max())        # clamp to curve ends
        y_interp = np.interp(tgt, x, y)            # linear interpolation
        tmp = gg.copy()
        tmp["swap_rate"] = y_interp
        out.append(tmp)
    return pd.concat(out, ignore_index=True) if out else gilts.assign(swap_rate=np.nan)

gilt_ts = attach_swap_at_tenor(g, s)
# compute ASW (same units as inputs; we convert to bp later)
gilt_ts["asw"] = gilt_ts["yld"] - gilt_ts["swap_rate"]

# ---------------- 4) Build auction panel ----------------
def build_panel(gilt_ts: pd.DataFrame, calendar_df: pd.DataFrame,
                window=(-8,8)) -> pd.DataFrame:
    rows = []
    cal = calendar_df.copy()
    for _, a in cal.iterrows():
        gi = gilt_ts[gilt_ts["series_id"] == a["series_id"]].sort_values("date")
        dates = gi["date"].unique().tolist()
        if a["auction_dt"] not in dates:
            # auction date missing in this series — skip
            continue
        pos = dates.index(a["auction_dt"])
        for k, d in enumerate(dates):
            rel = k - pos
            if window[0] <= rel <= window[1]:
                # average if multiple prints in a day
                asw_val = gi.loc[gi["date"] == d, "asw"].mean()
                rows.append({
                    "auction_dt": a["auction_dt"],
                    "series_id": a["series_id"],
                    "date": d,
                    "rel_day": rel,
                    "asw": asw_val,
                    "bucket": a.get("bucket", None)
                })
    return pd.DataFrame(rows)

panel = build_panel(gilt_ts, calendar_df, window=WINDOW)

# ---------------- 5) Concession vs baseline ----------------
def make_concession_panel(panel: pd.DataFrame, metric="asw",
                          baseline_rel=BASELINE_REL, in_bp=True, bp_scale=100.0):
    p = panel.copy()
    base = (p[p["rel_day"] == baseline_rel]
            .groupby(["auction_dt","series_id"])[metric]
            .mean()
            .rename("baseline")
            .reset_index())
    p = p.merge(base, on=["auction_dt","series_id"], how="left")
    p["concession"] = p[metric] - p["baseline"]
    if in_bp:
        p["concession"] = p["concession"] * bp_scale
    return p

cons_panel = make_concession_panel(panel, metric="asw", baseline_rel=BASELINE_REL,
                                   in_bp=IN_BP, bp_scale=BP_SCALE)

# ---------------- 6) Plot like your example ----------------
def plot_concession(cons_panel, buckets=("Long","Short")):
    fig, axes = plt.subplots(len(buckets), 1, figsize=(9, 8), sharex=True)
    if len(buckets) == 1: axes = [axes]
    for ax, b in zip(axes, buckets):
        q = cons_panel if b is None else cons_panel[cons_panel["bucket"] == b]
        if q.empty:
            ax.set_title(f"ASW concession = f(t) — {b} (no data)")
            continue
        grp = q.groupby("rel_day")["concession"]
        stats = pd.DataFrame({
            "mean": grp.mean(),
            "q75": grp.quantile(0.75),
            "q25": grp.quantile(0.25),
        }).reset_index()
        ax.plot(stats["rel_day"], stats["mean"], label="mean")
        ax.plot(stats["rel_day"], stats["q75"], linestyle="--", label="0.75 quantile")
        ax.plot(stats["rel_day"], stats["q25"], linestyle="--", label="0.25 quantile")
        ax.axvline(0, linestyle="--", color="k", alpha=0.6)
        ax.set_title(f"ASW concession = f(t) — {b}")
        ax.set_ylabel("Concession (bp)")
        ax.legend(loc="upper left")
    axes[-1].set_xlabel("Trading days around auction (T=0)")
    plt.tight_layout()
    return fig

# Example:
# plot_concession(cons_panel, buckets=("Long","Short"))
# plt.show()





# get unique series/tenors from asw_df
series_meta = asw_df.drop_duplicates(["series_id", "tenor_years"])

def pick_series(row):
    cands = series_meta[series_meta["tenor_years"] == row["tenor_years"]]
    return cands.iloc[0]["series_id"] if not cands.empty else None

# assign series_id from asw_df
calendar_df["series_id"] = calendar_df.apply(pick_series, axis=1)

# bring tenor_years from swap_df into calendar_df
calendar_df = calendar_df.merge(
    swap_df[["tenor_years"]].drop_duplicates(),  # unique tenors from swap_df
    how="left",
    left_on="tenor_years", 
    right_on="tenor_years"
)

# drop rows without series_id
cal_matched = calendar_df.dropna(subset=["series_id", "tenor_years"])
